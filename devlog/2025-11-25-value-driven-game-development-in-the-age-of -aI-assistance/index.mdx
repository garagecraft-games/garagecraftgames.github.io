---
title: "AI Assistance in Game Development"
description: "Thoughts on keeping the craft in craftsmanship when AI tools are everywhere"
tags: [devlog, thoughts]
keywords: [ai, software craftsmanship, game development, indiedev, github copilot, claude, manifesto]
authors: [thorstensuckow]
---

import {SocialLinks} from "../../src/components/SocialLinks";

I use [GitHub Copilot](https://github.com/features/copilot) mainly for Code Reviews. I think it's tremendously helpful when working on a solo project with a large codebase as it hints at typos and logic issues that easily slip under the radar when writing only coarse-grained tests for the sake of it. I also tried [Claude](https://claude.ai) and [Gemini](https://gemini.google.com). All those tools are sometimes helpful, sometimes annoying.

What's been on my mind: when I accept code I haven't thought through myself - do I still understand what I'm actually building?

<!--truncate-->

With [helios](https://helios.garagecraft.games) being the education project it is, understanding is the whole point. All those [articles on my personal website](https://thorsten.suckow-homberg.de) on computer graphics and software design - I'm not writing them because I already know this stuff, but because I want to learn it. If an AI generates my transformation matrix, I've learned nothing. (Might as well just use Unity.)

Sure, for boilerplate or when I'm writing the same unit test for the third time, Copilot is great. But architecture decisions? I want to think those through myself.

I wrote something about this: [The Manifesto for AI-Augmented Software Craftsmanship](https://ai-manifesto.software-craftsmanship.dev). It's about not forgetting why we're doing this in the first place.

More on that [here](https://thorsten.suckow-homberg.de/blog/manifesto-for-ai-augmented-software-craftsmanship).

<SocialLinks />
